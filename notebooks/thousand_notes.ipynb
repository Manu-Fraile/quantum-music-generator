{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6b72e-df04-4f43-aef0-4c907d30b733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio file 'thousand_note_quantum_music.wav' generated!\n"
     ]
    }
   ],
   "source": [
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit_aer import Aer\n",
    "from pydub import AudioSegment\n",
    "from pydub.generators import Sine\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Define the note-to-frequency mapping for Do Major scale\n",
    "note_frequencies = {\n",
    "    'Do': 261.63,\n",
    "    'Re': 293.66,\n",
    "    'Mi': 329.63,\n",
    "    'Fa': 349.23,\n",
    "    'Sol': 392.00,\n",
    "    'La': 440.00,\n",
    "    'Si': 493.88,\n",
    "    'Do_high': 523.25\n",
    "}\n",
    "\n",
    "# Set the duration for each note (in milliseconds)\n",
    "note_duration = 100  # half a second per note\n",
    "\n",
    "# Step 1: Create a 3-qubit quantum circuit\n",
    "circuit = QuantumCircuit(3, 3)\n",
    "\n",
    "# Step 2: Apply Hadamard gates to each qubit for superposition\n",
    "circuit.h(0)\n",
    "circuit.h(1)\n",
    "circuit.h(2)\n",
    "\n",
    "# Step 3: Measure each qubit\n",
    "circuit.measure([0, 1, 2], [0, 1, 2])\n",
    "\n",
    "# Step 4: Use the Aer simulator\n",
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# Transpile the circuit for the simulator\n",
    "transpiled_circuit = transpile(circuit, simulator)\n",
    "\n",
    "# Run the circuit with 1000 shots to generate many notes\n",
    "job = simulator.run(transpiled_circuit, shots=1000)\n",
    "result = job.result()\n",
    "counts = result.get_counts()\n",
    "\n",
    "# Define the state-to-note mapping based on measured states\n",
    "note_mapping = {\n",
    "    '000': 'Do', '001': 'Re', '010': 'Mi', '011': 'Fa',\n",
    "    '100': 'Sol', '101': 'La', '110': 'Si', '111': 'Do_high'\n",
    "}\n",
    "\n",
    "# Initialize an empty audio segment to hold the music\n",
    "audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "# Generate and append notes to the audio segment until we reach 1000 notes\n",
    "note_count = 0\n",
    "while note_count < 1000:\n",
    "    for state, frequency in counts.items():\n",
    "        # Continue only if we haven't reached 1000 notes yet\n",
    "        if note_count >= 1000:\n",
    "            break\n",
    "        \n",
    "        note = note_mapping[state]\n",
    "        \n",
    "        # Random chance of inserting a rest\n",
    "        if random.random() < 0.2:  # 20% chance of rest\n",
    "            audio += AudioSegment.silent(duration=note_duration)\n",
    "        else:\n",
    "            frequency = note_frequencies[note]\n",
    "            sine_wave = Sine(frequency).to_audio_segment(duration=note_duration)\n",
    "            # Apply fade in/out for smooth transitions\n",
    "            sine_wave = sine_wave.fade_in(50).fade_out(50)\n",
    "            audio += sine_wave\n",
    "            \n",
    "        note_count += 1\n",
    "\n",
    "# Save the generated music to a new .wav file\n",
    "audio.export(\"thousand_note_quantum_music.wav\", format=\"wav\")\n",
    "print(\"Audio file 'thousand_note_quantum_music.wav' generated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f57bd-4876-41da-a5bd-79bafec0f844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
